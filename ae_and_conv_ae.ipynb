{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    import PyQt5.QtCore\n",
    "    %matplotlib qt\n",
    "except ImportError:\n",
    "    %matplotlib inline\n",
    "import keras\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "from mne.channels import make_standard_montage\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data_dir = os.path.dirname(\"./data/\")\n",
    "data_files = os.listdir(data_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def annotations_from_eGUI(raw, egui):\n",
    "    codes = []\n",
    "    starts = []\n",
    "\n",
    "    current_state = None\n",
    "\n",
    "    for i in range(len(egui)):\n",
    "        if egui[i][0] != current_state:\n",
    "            starts.append(i)\n",
    "            current_state = egui[i][0]\n",
    "            codes.append(str(egui[i][0]))\n",
    "\n",
    "    starts.append(len(egui))\n",
    "    codes = np.array(codes)\n",
    "    sf = raw.info.get('sfreq')\n",
    "    starts = np.array(starts) / sf\n",
    "    durations = starts[1:] - starts[:-1]\n",
    "    starts = starts[:-1]\n",
    "\n",
    "    raw.set_annotations(mne.Annotations(onset=starts, duration=durations, description=codes))\n",
    "\n",
    "\n",
    "def raw_from_mat(file):\n",
    "    mat = loadmat(os.path.join(data_dir, file))\n",
    "\n",
    "    sampling_freq = mat[\"o\"][0][0][2][0][0]\n",
    "    n_samples = mat[\"o\"][0][0][3][0][0]\n",
    "    ch_names = [element[0][0] for element in mat[\"o\"][0][0][6]]\n",
    "\n",
    "    df = pd.DataFrame(mat[\"o\"][0][0][5], columns=ch_names)\n",
    "    df = df.drop(columns=[\"X5\"])\n",
    "    df = df.T\n",
    "    ch_names.remove(\"X5\")\n",
    "\n",
    "    ch_types = ['eeg'] * 21\n",
    "    info = mne.create_info(ch_names, ch_types=ch_types, sfreq=sampling_freq)\n",
    "    raw = mne.io.RawArray(df.to_numpy(), info)\n",
    "\n",
    "    montage = make_standard_montage(\"standard_prefixed\")\n",
    "    raw.set_montage(montage)\n",
    "\n",
    "    raw.load_data().set_eeg_reference(ref_channels='average')\n",
    "    annotations_from_eGUI(raw, mat[\"o\"][0][0][4])\n",
    "    return raw\n",
    "\n",
    "\n",
    "def filter_raw(raw):\n",
    "    return raw.load_data().filter(0.1, 30, method=\"fir\", phase=\"zero-double\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=21, n_times=664400\n",
      "    Range : 0 ... 664399 =      0.000 ...  3321.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=664600\n",
      "    Range : 0 ... 664599 =      0.000 ...  3322.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=662400\n",
      "    Range : 0 ... 662399 =      0.000 ...  3311.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=667600\n",
      "    Range : 0 ... 667599 =      0.000 ...  3337.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=734400\n",
      "    Range : 0 ... 734399 =      0.000 ...  3671.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=667000\n",
      "    Range : 0 ... 666999 =      0.000 ...  3334.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=678400\n",
      "    Range : 0 ... 678399 =      0.000 ...  3391.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=475000\n",
      "    Range : 0 ... 474999 =      0.000 ...  2374.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=391800\n",
      "    Range : 0 ... 391799 =      0.000 ...  1958.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=285800\n",
      "    Range : 0 ... 285799 =      0.000 ...  1428.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n"
     ]
    }
   ],
   "source": [
    "raw_NoMT = [raw_from_mat(file) for file in data_files if \"NoMT\" in file]\n",
    "raw_FREEFORM = [raw_from_mat(file) for file in data_files if \"FREEFORM\" in file]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_epochs(raw):\n",
    "    metadata_tmin, metadata_tmax = -1, 1\n",
    "\n",
    "    all_events, all_event_id = mne.events_from_annotations(raw)\n",
    "    metadata, events, event_id = mne.epochs.make_metadata(\n",
    "        events=all_events,\n",
    "        event_id=all_event_id,\n",
    "        tmin=metadata_tmin,\n",
    "        tmax=metadata_tmax,\n",
    "        sfreq=raw.info[\"sfreq\"],\n",
    "    )\n",
    "    return mne.Epochs(raw, events, event_id, reject_by_annotation=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1931 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1919 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1925 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1935 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1935 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1935 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1933 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '99']\n",
      "Not setting metadata\n",
      "1481 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '99']\n",
      "Not setting metadata\n",
      "1383 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '99']\n",
      "Not setting metadata\n",
      "1409 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "epochs_NoMT = [get_epochs(file) for file in raw_NoMT]\n",
    "epochs_FREEFORM = [get_epochs(file) for file in raw_FREEFORM]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1931 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1919 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1925 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1935 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1935 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1935 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1933 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '99']\n",
      "Not setting metadata\n",
      "1481 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '99']\n",
      "Not setting metadata\n",
      "1383 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '99']\n",
      "Not setting metadata\n",
      "1409 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "epochs_NoMT = [get_epochs(file) for file in raw_NoMT]\n",
    "epochs_FREEFORM = [get_epochs(file) for file in raw_FREEFORM]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 1931 events and 141 original time points ...\n",
      "1 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/plain": "865.3172938443672"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_NoMT[0].get_data().max()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 1481 events and 141 original time points ...\n",
      "1 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/plain": "158.92792102206735"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_FREEFORM[0].get_data().max()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 1930 events and 141 original time points ...\n",
      "Using data from preloaded Raw for 1919 events and 141 original time points ...\n",
      "1 bad epochs dropped\n",
      "Using data from preloaded Raw for 1925 events and 141 original time points ...\n",
      "1 bad epochs dropped\n",
      "Using data from preloaded Raw for 1935 events and 141 original time points ...\n",
      "1 bad epochs dropped\n",
      "Using data from preloaded Raw for 1935 events and 141 original time points ...\n",
      "1 bad epochs dropped\n",
      "Using data from preloaded Raw for 1935 events and 141 original time points ...\n",
      "1 bad epochs dropped\n",
      "Using data from preloaded Raw for 1933 events and 141 original time points ...\n",
      "1 bad epochs dropped\n",
      "Using data from preloaded Raw for 1480 events and 141 original time points ...\n",
      "Using data from preloaded Raw for 1383 events and 141 original time points ...\n",
      "1 bad epochs dropped\n",
      "Using data from preloaded Raw for 1409 events and 141 original time points ...\n",
      "1 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "epochs_data_NOMT = [file.get_data() for file in epochs_NoMT]\n",
    "epochs_data_FREEFORM = [file.get_data() for file in epochs_FREEFORM]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "stacked_NOMT = np.vstack(epochs_data_NOMT)\n",
    "stacked_FREEFORM = np.vstack(epochs_data_FREEFORM)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(13506, 21, 141)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_NOMT.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(4270, 21, 141)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_FREEFORM.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "np.random.shuffle(stacked_NOMT)\n",
    "np.random.shuffle(stacked_FREEFORM)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "X_nomt_train = stacked_NOMT[:12000]\n",
    "X_nomt_test = stacked_NOMT[12000:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "X_free = stacked_FREEFORM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# make Freeform test set same length as NoMT\n",
    "idy = random.sample(range(0, len(X_free)), X_nomt_test.shape[0])\n",
    "X_free_test = X_free[idy]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "(1506, 21, 141)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_free_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def calc_accuracy(a, b, th):\n",
    "    first = [1 if i < th else 0 for i in a]\n",
    "    last = [1 if i > th else 0 for i in b]\n",
    "    return sum(first + last) / len(first + last)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Standard Autoencoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.42555168e+00  2.67063879e+00 -1.50269454e+00 ...  3.44254355e+00\n",
      "    1.20120674e+01  1.12906388e+01]\n",
      "  [-5.35384437e+00 -4.33765389e+00 -1.67098722e+00 ...  2.75425087e+00\n",
      "    7.28377468e+00  4.69234611e+00]\n",
      "  [ 6.78106852e-01  4.14297329e-01 -1.79036005e-01 ...  6.05620209e+00\n",
      "    5.44572590e+00  1.94429733e+00]\n",
      "  ...\n",
      "  [ 7.57131243e-01  1.49332172e+00 -4.00116144e-02 ...  1.67522648e+00\n",
      "    2.34475029e+00  3.13321719e-01]\n",
      "  [ 2.09322880e+00  3.02941928e+00  2.28608595e+00 ...  4.54132404e+00\n",
      "    2.32084785e+00  2.11941928e+00]\n",
      "  [ 2.49054588e+00  2.40673635e+00  8.43403020e-01 ...  4.88864111e+00\n",
      "    3.31816492e+00  4.41673635e+00]]\n",
      "\n",
      " [[-3.02198606e+00 -5.48674797e+00 -2.42103368e+00 ...  3.37718235e+01\n",
      "    3.27508711e+01  2.54413473e+01]\n",
      "  [ 9.12069686e+00  1.65934959e-01  3.05164925e+00 ...  5.55345064e+01\n",
      "    5.12635540e+01  4.61340302e+01]\n",
      "  [-2.23491289e+00 -3.13967480e+00 -3.35396051e+00 ...  8.32889663e+00\n",
      "    8.55794425e+00  1.63842044e+00]\n",
      "  ...\n",
      "  [-3.48003484e+00 -6.33479675e+00 -4.57908246e+00 ...  2.65737747e+01\n",
      "    2.46628223e+01  2.00332985e+01]\n",
      "  [-1.78320557e+00 -2.82796748e+00 -3.32225319e+00 ... -1.06393961e+01\n",
      "   -1.13203484e+01 -9.25987224e+00]\n",
      "  [-1.26686411e+00  1.40837398e+00  1.01408827e+00 ... -1.79030546e+01\n",
      "   -1.77240070e+01 -1.64335308e+01]]\n",
      "\n",
      " [[ 5.24864111e+00  8.92578397e+00  7.88102207e+00 ... -2.79231127e+00\n",
      "   -1.98278746e+00 -2.52787456e-01]\n",
      "  [ 8.33425087e+00  8.62139373e+00  1.02466318e+01 ...  1.25832985e+01\n",
      "    1.15228223e+01  1.08928223e+01]\n",
      "  [ 2.02473868e+00  3.53188153e+00  3.90711963e+00 ... -1.21621370e+00\n",
      "    4.33310105e-01  2.81331010e+00]\n",
      "  ...\n",
      "  [ 4.99156794e+00  7.71871080e+00  7.18394890e+00 ... -4.30938444e+00\n",
      "   -4.12986063e+00 -2.01986063e+00]\n",
      "  [ 4.31156794e+00  4.77871080e+00  5.54394890e+00 ... -7.45938444e+00\n",
      "   -8.14986063e+00 -6.27986063e+00]\n",
      "  [ 2.46108014e+00  1.28822300e+00  1.30346109e+00 ...  5.19012776e+00\n",
      "    3.82965157e+00  2.28965157e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.73089431e-01  1.88357724e+00 -2.02613240e-01 ... -2.50975610e+00\n",
      "   -4.64975610e+00 -8.97261324e+00]\n",
      "  [-2.76894309e+00 -2.90227642e+00 -3.64846690e+00 ...  6.96439024e+00\n",
      "    4.34439024e+00  2.45153310e+00]\n",
      "  [ 1.85813008e+00 -1.93520325e+00 -1.29139373e+00 ... -3.28536585e-01\n",
      "   -7.68536585e-01 -3.41393728e-01]\n",
      "  ...\n",
      "  [ 1.57178862e+00  1.00845528e+00  6.62264808e-01 ... -1.83487805e+00\n",
      "   -4.02487805e+00 -6.14773519e+00]\n",
      "  [ 1.07349593e+00  5.17016260e+00  5.12397213e+00 ...  7.43682927e+00\n",
      "    7.94682927e+00  5.58397213e+00]\n",
      "  [-3.17089431e+00  6.05772358e-01  1.23958188e+00 ...  2.03424390e+01\n",
      "    2.15724390e+01  2.17795819e+01]]\n",
      "\n",
      " [[-1.80546341e+01 -9.31987224e+00  5.28222997e-01 ...  3.60172706e+01\n",
      "    2.53648897e+01  1.43125087e+01]\n",
      "  [-1.20334146e+01 -5.54865273e+00 -7.15055749e+00 ...  3.42284901e+01\n",
      "    3.17661092e+01  3.73737282e+01]\n",
      "  [ 6.72073171e+00  3.43549361e+00  5.93358885e+00 ...  4.85263647e+00\n",
      "    1.01102555e+01  1.62478746e+01]\n",
      "  ...\n",
      "  [ 2.69512195e-01 -3.71572590e+00 -3.17630662e-01 ...  5.62141696e+00\n",
      "    1.02890360e+01  5.50665505e+00]\n",
      "  [-1.64000000e+00 -3.91523810e+00 -5.32714286e+00 ...  3.00619048e+01\n",
      "    3.66095238e+01  3.18371429e+01]\n",
      "  [-2.16804878e+00 -5.01328688e+00 -7.15519164e+00 ...  2.63938560e+01\n",
      "    2.85814750e+01  2.83390941e+01]]\n",
      "\n",
      " [[-1.66903600e+00 -2.02236934e+00 -8.69988386e-01 ... -1.36380836e+01\n",
      "   -9.53760743e+00 -6.13808362e+00]\n",
      "  [-6.37757259e+00 -9.23090592e+00 -3.33852497e+00 ... -7.93662021e+00\n",
      "   -1.23761440e+01 -1.07166202e+01]\n",
      "  [-8.90255517e-01  1.51641115e+00  1.83879210e+00 ... -8.66930314e+00\n",
      "   -3.76882695e+00 -7.29303136e-01]\n",
      "  ...\n",
      "  [-3.59036005e-01 -1.59236934e+00  4.90011614e-01 ... -1.30180836e+01\n",
      "   -9.90760743e+00 -6.18808362e+00]\n",
      "  [ 7.69218351e+00  6.15885017e+00  5.73123113e+00 ... -8.37686411e+00\n",
      "   -5.13638792e+00 -4.08686411e+00]\n",
      "  [ 3.47754936e+00  4.87421603e+00  5.11659698e+00 ...  4.27850174e+00\n",
      "    4.86897793e+00  2.49850174e+00]]]\n",
      "865.3172938443672\n",
      "122.05500580720093\n",
      "106.87045\n",
      "20.985914\n"
     ]
    }
   ],
   "source": [
    "layer = layers.Normalization()\n",
    "layer1 = layers.Normalization()\n",
    "layer.adapt(X_nomt_train.astype(float))\n",
    "layer1.adapt(X_free_test.astype(float))\n",
    "\n",
    "print(X_nomt_train)\n",
    "print(np.max(X_nomt_train))\n",
    "print(np.max(X_free_test))\n",
    "print(np.max(layer(X_nomt_train)))\n",
    "print(np.max(layer1(X_free_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "latent_dim = 512\n",
    "keras.backend.clear_session()\n",
    "\n",
    "\n",
    "class Autoencoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(1024, activation='gelu'),\n",
    "            layers.Dense(512, activation='gelu'),\n",
    "            layers.Dense(64, activation='gelu'),\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Dense(512, activation='gelu'),\n",
    "            layers.Dense(1024, activation='gelu'),\n",
    "            layers.Dense(21 * 141, activation='linear'),\n",
    "            layers.Reshape((21, 141))\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "autoencoder = Autoencoder(latent_dim)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.5668 - val_loss: 0.4270\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.4495 - val_loss: 0.4038\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.4169 - val_loss: 0.3569\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 5s 29ms/step - loss: 0.3681 - val_loss: 0.3828\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.3749 - val_loss: 0.3430\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.3713 - val_loss: 0.3313\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.3706 - val_loss: 0.3583\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 6s 31ms/step - loss: 0.3762 - val_loss: 0.3333\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.3590 - val_loss: 0.3254\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.3460 - val_loss: 0.3293\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x17d2d7c5ac8>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "autoencoder.compile(optimizer=opt, loss=losses.MeanSquaredError())\n",
    "autoencoder.fit(layer(X_nomt_train), layer(X_nomt_train),\n",
    "                epochs=10,\n",
    "                batch_size=64,\n",
    "                shuffle=True,\n",
    "                validation_data=(layer(X_nomt_test[:1000]), layer(X_nomt_test[:1000])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################\n",
      "##############\n",
      "0.34291136\n",
      "0.61085016\n"
     ]
    }
   ],
   "source": [
    "err = []\n",
    "err2 = []\n",
    "for i in X_nomt_train:\n",
    "    # need to expand here because the flatten layer assumes that the first dimension is the number of samples\n",
    "    i = np.expand_dims(i, axis=0)\n",
    "    encoded = autoencoder.encoder(layer(i)).numpy()\n",
    "    decoded = autoencoder.decoder(encoded).numpy()\n",
    "    #print(\"Error:\",(np.square(i-decoded)).mean())\n",
    "    err.append((np.square(layer(i) - decoded)).mean())\n",
    "print(\"###################\")\n",
    "\n",
    "for j in X_free_test:\n",
    "    j = np.expand_dims(j, axis=0)\n",
    "    encoded = autoencoder.encoder(layer1(j)).numpy()\n",
    "    decoded = autoencoder.decoder(encoded).numpy()\n",
    "    #print(\"Error:\",(np.square(layer(j)-decoded)).mean())\n",
    "    err2.append((np.square(layer1(j) - decoded)).mean())\n",
    "print(\"##############\")\n",
    "print(np.array(err).mean())\n",
    "print(np.array(err2).mean())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8157855767806901"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_accuracy(err, err2, np.mean([np.array(err).mean(), np.array(err2).mean()]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convolutional Autoencoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(1506, 141, 21)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_nomt_train = np.moveaxis(X_nomt_train, 1, 2)\n",
    "X_nomt_test = np.moveaxis(X_nomt_test, 1, 2)\n",
    "X_free_test = np.moveaxis(X_free_test, 1, 2)\n",
    "X_free_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.42555168e+00 -5.35384437e+00  6.78106852e-01 ...  7.57131243e-01\n",
      "    2.09322880e+00  2.49054588e+00]\n",
      "  [ 2.67063879e+00 -4.33765389e+00  4.14297329e-01 ...  1.49332172e+00\n",
      "    3.02941928e+00  2.40673635e+00]\n",
      "  [-1.50269454e+00 -1.67098722e+00 -1.79036005e-01 ... -4.00116144e-02\n",
      "    2.28608595e+00  8.43403020e-01]\n",
      "  ...\n",
      "  [ 3.44254355e+00  2.75425087e+00  6.05620209e+00 ...  1.67522648e+00\n",
      "    4.54132404e+00  4.88864111e+00]\n",
      "  [ 1.20120674e+01  7.28377468e+00  5.44572590e+00 ...  2.34475029e+00\n",
      "    2.32084785e+00  3.31816492e+00]\n",
      "  [ 1.12906388e+01  4.69234611e+00  1.94429733e+00 ...  3.13321719e-01\n",
      "    2.11941928e+00  4.41673635e+00]]\n",
      "\n",
      " [[-3.02198606e+00  9.12069686e+00 -2.23491289e+00 ... -3.48003484e+00\n",
      "   -1.78320557e+00 -1.26686411e+00]\n",
      "  [-5.48674797e+00  1.65934959e-01 -3.13967480e+00 ... -6.33479675e+00\n",
      "   -2.82796748e+00  1.40837398e+00]\n",
      "  [-2.42103368e+00  3.05164925e+00 -3.35396051e+00 ... -4.57908246e+00\n",
      "   -3.32225319e+00  1.01408827e+00]\n",
      "  ...\n",
      "  [ 3.37718235e+01  5.55345064e+01  8.32889663e+00 ...  2.65737747e+01\n",
      "   -1.06393961e+01 -1.79030546e+01]\n",
      "  [ 3.27508711e+01  5.12635540e+01  8.55794425e+00 ...  2.46628223e+01\n",
      "   -1.13203484e+01 -1.77240070e+01]\n",
      "  [ 2.54413473e+01  4.61340302e+01  1.63842044e+00 ...  2.00332985e+01\n",
      "   -9.25987224e+00 -1.64335308e+01]]\n",
      "\n",
      " [[ 5.24864111e+00  8.33425087e+00  2.02473868e+00 ...  4.99156794e+00\n",
      "    4.31156794e+00  2.46108014e+00]\n",
      "  [ 8.92578397e+00  8.62139373e+00  3.53188153e+00 ...  7.71871080e+00\n",
      "    4.77871080e+00  1.28822300e+00]\n",
      "  [ 7.88102207e+00  1.02466318e+01  3.90711963e+00 ...  7.18394890e+00\n",
      "    5.54394890e+00  1.30346109e+00]\n",
      "  ...\n",
      "  [-2.79231127e+00  1.25832985e+01 -1.21621370e+00 ... -4.30938444e+00\n",
      "   -7.45938444e+00  5.19012776e+00]\n",
      "  [-1.98278746e+00  1.15228223e+01  4.33310105e-01 ... -4.12986063e+00\n",
      "   -8.14986063e+00  3.82965157e+00]\n",
      "  [-2.52787456e-01  1.08928223e+01  2.81331010e+00 ... -2.01986063e+00\n",
      "   -6.27986063e+00  2.28965157e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.73089431e-01 -2.76894309e+00  1.85813008e+00 ...  1.57178862e+00\n",
      "    1.07349593e+00 -3.17089431e+00]\n",
      "  [ 1.88357724e+00 -2.90227642e+00 -1.93520325e+00 ...  1.00845528e+00\n",
      "    5.17016260e+00  6.05772358e-01]\n",
      "  [-2.02613240e-01 -3.64846690e+00 -1.29139373e+00 ...  6.62264808e-01\n",
      "    5.12397213e+00  1.23958188e+00]\n",
      "  ...\n",
      "  [-2.50975610e+00  6.96439024e+00 -3.28536585e-01 ... -1.83487805e+00\n",
      "    7.43682927e+00  2.03424390e+01]\n",
      "  [-4.64975610e+00  4.34439024e+00 -7.68536585e-01 ... -4.02487805e+00\n",
      "    7.94682927e+00  2.15724390e+01]\n",
      "  [-8.97261324e+00  2.45153310e+00 -3.41393728e-01 ... -6.14773519e+00\n",
      "    5.58397213e+00  2.17795819e+01]]\n",
      "\n",
      " [[-1.80546341e+01 -1.20334146e+01  6.72073171e+00 ...  2.69512195e-01\n",
      "   -1.64000000e+00 -2.16804878e+00]\n",
      "  [-9.31987224e+00 -5.54865273e+00  3.43549361e+00 ... -3.71572590e+00\n",
      "   -3.91523810e+00 -5.01328688e+00]\n",
      "  [ 5.28222997e-01 -7.15055749e+00  5.93358885e+00 ... -3.17630662e-01\n",
      "   -5.32714286e+00 -7.15519164e+00]\n",
      "  ...\n",
      "  [ 3.60172706e+01  3.42284901e+01  4.85263647e+00 ...  5.62141696e+00\n",
      "    3.00619048e+01  2.63938560e+01]\n",
      "  [ 2.53648897e+01  3.17661092e+01  1.01102555e+01 ...  1.02890360e+01\n",
      "    3.66095238e+01  2.85814750e+01]\n",
      "  [ 1.43125087e+01  3.73737282e+01  1.62478746e+01 ...  5.50665505e+00\n",
      "    3.18371429e+01  2.83390941e+01]]\n",
      "\n",
      " [[-1.66903600e+00 -6.37757259e+00 -8.90255517e-01 ... -3.59036005e-01\n",
      "    7.69218351e+00  3.47754936e+00]\n",
      "  [-2.02236934e+00 -9.23090592e+00  1.51641115e+00 ... -1.59236934e+00\n",
      "    6.15885017e+00  4.87421603e+00]\n",
      "  [-8.69988386e-01 -3.33852497e+00  1.83879210e+00 ...  4.90011614e-01\n",
      "    5.73123113e+00  5.11659698e+00]\n",
      "  ...\n",
      "  [-1.36380836e+01 -7.93662021e+00 -8.66930314e+00 ... -1.30180836e+01\n",
      "   -8.37686411e+00  4.27850174e+00]\n",
      "  [-9.53760743e+00 -1.23761440e+01 -3.76882695e+00 ... -9.90760743e+00\n",
      "   -5.13638792e+00  4.86897793e+00]\n",
      "  [-6.13808362e+00 -1.07166202e+01 -7.29303136e-01 ... -6.18808362e+00\n",
      "   -4.08686411e+00  2.49850174e+00]]]\n",
      "865.3172938443672\n",
      "122.05500580720093\n",
      "69.13005\n",
      "14.232102\n"
     ]
    }
   ],
   "source": [
    "# Adjust normalization layer to different shape\n",
    "layer = layers.Normalization()\n",
    "layer1 = layers.Normalization()\n",
    "layer.adapt(X_nomt_train.astype(float))\n",
    "layer1.adapt(X_free_test.astype(float))\n",
    "\n",
    "print(X_nomt_train)\n",
    "print(np.max(X_nomt_train))\n",
    "print(np.max(X_free_test))\n",
    "print(np.max(layer(X_nomt_train)))\n",
    "print(np.max(layer1(X_free_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "latent_dim = 512\n",
    "keras.backend.clear_session()\n",
    "\n",
    "\n",
    "class ConvAutoencoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Input(shape=(X_nomt_train.shape[1], X_nomt_train.shape[2])),  # 141, 21\n",
    "            layers.Conv1D(14, 3, activation=None, padding='same', strides=1),\n",
    "            layers.LeakyReLU(),\n",
    "            layers.Conv1D(7, 3, activation=None, padding='same', strides=1),\n",
    "            layers.LeakyReLU(),\n",
    "        ])\n",
    "\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Conv1DTranspose(7, kernel_size=3, strides=1, activation=None, padding='same'),\n",
    "            layers.LeakyReLU(),\n",
    "            layers.Conv1DTranspose(14, kernel_size=3, strides=1, activation=None, padding='same'),\n",
    "            layers.LeakyReLU(),\n",
    "            layers.Conv1D(X_nomt_train.shape[2], kernel_size=3, activation=None, padding='same'),\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "conv_autoencoder = ConvAutoencoder(latent_dim)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 141, 14)           896       \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 141, 14)           0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 141, 7)            301       \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 141, 7)            0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,197\n",
      "Trainable params: 1,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_autoencoder.encoder.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "conv_autoencoder.compile(optimizer=opt, loss=losses.MeanSquaredError())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "188/188 [==============================] - 3s 12ms/step - loss: 0.5577 - val_loss: 0.3651\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.3592 - val_loss: 0.3046\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.3076 - val_loss: 0.2680\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.2728 - val_loss: 0.2406\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.2475 - val_loss: 0.2221\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.2302 - val_loss: 0.2110\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.2198 - val_loss: 0.2036\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.2122 - val_loss: 0.1976\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.2066 - val_loss: 0.1918\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.2016 - val_loss: 0.1897\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x17d1d1c8288>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_autoencoder.fit(layer(X_nomt_train), layer(X_nomt_train),\n",
    "                     epochs=10,\n",
    "                     batch_size=64,\n",
    "                     shuffle=True,\n",
    "                     validation_data=(layer(X_nomt_test[:1000]), layer(X_nomt_test[:1000])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################\n",
      "##############\n",
      "0.19847809\n",
      "0.26387638\n"
     ]
    }
   ],
   "source": [
    "err = []\n",
    "err2 = []\n",
    "for i in X_nomt_train:\n",
    "    # need to expand here because the flatten layer assumes that the first dimension is the number of samples\n",
    "    i = np.expand_dims(i, axis=0)\n",
    "    encoded = conv_autoencoder.encoder(layer(i)).numpy()\n",
    "    decoded = conv_autoencoder.decoder(encoded).numpy()\n",
    "    #print(\"Error:\",(np.square(i-decoded)).mean())\n",
    "    err.append((np.square(layer(i) - decoded)).mean())\n",
    "print(\"###################\")\n",
    "\n",
    "for j in X_free_test:\n",
    "    j = np.expand_dims(j, axis=0)\n",
    "    encoded = conv_autoencoder.encoder(layer1(j)).numpy()\n",
    "    decoded = conv_autoencoder.decoder(encoded).numpy()\n",
    "    #print(\"Error:\",(np.square(layer(j)-decoded)).mean())\n",
    "    err2.append((np.square(layer1(j) - decoded)).mean())\n",
    "print(\"##############\")\n",
    "print(np.array(err).mean())\n",
    "print(np.array(err2).mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7764697171627425"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_accuracy(err, err2, np.mean([np.array(err).mean(), np.array(err2).mean()]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8728713164519473"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_accuracy(err, err2, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aa137f996c322d810b0ba78b9855db9c260b81f9ff796e150df9906e831bb7ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}