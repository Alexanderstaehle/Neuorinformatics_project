{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    import PyQt5.QtCore\n",
    "    %matplotlib qt\n",
    "except ImportError:\n",
    "    %matplotlib inline\n",
    "import keras\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "from mne.channels import make_standard_montage\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.dirname(\"./data/\")\n",
    "data_files = os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def annotations_from_eGUI(raw, egui):\n",
    "    codes = []\n",
    "    starts = []\n",
    "\n",
    "    current_state = None\n",
    "\n",
    "    for i in range(len(egui)):\n",
    "        if egui[i][0] != current_state:\n",
    "            starts.append(i)\n",
    "            current_state = egui[i][0]\n",
    "            codes.append(str(egui[i][0]))\n",
    "\n",
    "    starts.append(len(egui))\n",
    "    codes = np.array(codes)\n",
    "    sf = raw.info.get('sfreq')\n",
    "    starts = np.array(starts) / sf\n",
    "    durations = starts[1:] - starts[:-1]\n",
    "    starts = starts[:-1]\n",
    "\n",
    "    raw.set_annotations(mne.Annotations(onset=starts, duration=durations, description=codes))\n",
    "\n",
    "\n",
    "def raw_from_mat(file):\n",
    "    mat = loadmat(os.path.join(data_dir, file))\n",
    "\n",
    "    sampling_freq = mat[\"o\"][0][0][2][0][0]\n",
    "    n_samples = mat[\"o\"][0][0][3][0][0]\n",
    "    ch_names = [element[0][0] for element in mat[\"o\"][0][0][6]]\n",
    "\n",
    "    df = pd.DataFrame(mat[\"o\"][0][0][5], columns=ch_names)\n",
    "    df = df.drop(columns=[\"X5\"])\n",
    "    df = df.T\n",
    "    ch_names.remove(\"X5\")\n",
    "\n",
    "    ch_types = ['eeg'] * 21\n",
    "    info = mne.create_info(ch_names, ch_types=ch_types, sfreq=sampling_freq)\n",
    "    raw = mne.io.RawArray(df.to_numpy(), info)\n",
    "\n",
    "    montage = make_standard_montage(\"standard_prefixed\")\n",
    "    raw.set_montage(montage)\n",
    "\n",
    "    raw.load_data().set_eeg_reference(ref_channels='average')\n",
    "    annotations_from_eGUI(raw, mat[\"o\"][0][0][4])\n",
    "    return raw\n",
    "\n",
    "\n",
    "def filter_raw(raw):\n",
    "    return raw.load_data().filter(0.1, 30, method=\"fir\", phase=\"zero-double\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=21, n_times=664400\n",
      "    Range : 0 ... 664399 =      0.000 ...  3321.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=664600\n",
      "    Range : 0 ... 664599 =      0.000 ...  3322.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=662400\n",
      "    Range : 0 ... 662399 =      0.000 ...  3311.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=667600\n",
      "    Range : 0 ... 667599 =      0.000 ...  3337.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=734400\n",
      "    Range : 0 ... 734399 =      0.000 ...  3671.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=667000\n",
      "    Range : 0 ... 666999 =      0.000 ...  3334.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=678400\n",
      "    Range : 0 ... 678399 =      0.000 ...  3391.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=475000\n",
      "    Range : 0 ... 474999 =      0.000 ...  2374.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=391800\n",
      "    Range : 0 ... 391799 =      0.000 ...  1958.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=285800\n",
      "    Range : 0 ... 285799 =      0.000 ...  1428.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n"
     ]
    }
   ],
   "source": [
    "raw_NoMT = [raw_from_mat(file) for file in data_files if \"NoMT\" in file]\n",
    "raw_FREEFORM = [raw_from_mat(file) for file in data_files if \"FREEFORM\" in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_epochs(raw, event_id):\n",
    "    metadata_tmin, metadata_tmax = -1, 1\n",
    "    all_events, all_event_id = mne.events_from_annotations(raw, event_id=event_id)\n",
    "    metadata, events, event_id = mne.epochs.make_metadata(\n",
    "        events=all_events,\n",
    "        event_id=event_id,\n",
    "        tmin=metadata_tmin,\n",
    "        tmax=metadata_tmax,\n",
    "        sfreq=raw.info[\"sfreq\"],\n",
    "    )\n",
    "    print(raw.info[\"sfreq\"])\n",
    "    return mne.Epochs(raw, events, event_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['0']\n",
      "200.0\n",
      "Not setting metadata\n",
      "966 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0']\n",
      "200.0\n",
      "Not setting metadata\n",
      "960 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0']\n",
      "200.0\n",
      "Not setting metadata\n",
      "963 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0']\n",
      "200.0\n",
      "Not setting metadata\n",
      "968 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0']\n",
      "200.0\n",
      "Not setting metadata\n",
      "968 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0']\n",
      "200.0\n",
      "Not setting metadata\n",
      "968 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0']\n",
      "200.0\n",
      "Not setting metadata\n",
      "967 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['1', '2']\n",
      "200.0\n",
      "Not setting metadata\n",
      "739 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['1', '2']\n",
      "200.0\n",
      "Not setting metadata\n",
      "688 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['1', '2']\n",
      "200.0\n",
      "Not setting metadata\n",
      "700 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['2']\n",
      "200.0\n",
      "Not setting metadata\n",
      "159 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['2']\n",
      "200.0\n",
      "Not setting metadata\n",
      "157 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['2']\n",
      "200.0\n",
      "Not setting metadata\n",
      "158 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['2']\n",
      "200.0\n",
      "Not setting metadata\n",
      "159 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['2']\n",
      "200.0\n",
      "Not setting metadata\n",
      "159 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['2']\n",
      "200.0\n",
      "Not setting metadata\n",
      "163 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['2']\n",
      "200.0\n",
      "Not setting metadata\n",
      "159 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "epochs_NoMT = [get_epochs(file, {\"0\": 1}) for file in raw_NoMT]\n",
    "epochs_FREEFORM = [get_epochs(file, {'1': 2, '2': 3}) for file in raw_FREEFORM]\n",
    "epochs_NOMT_only_code_2 = [get_epochs(file, {\"2\": 3}) for file in raw_NoMT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 966 events and 141 original time points ...\n",
      "1 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "865.3172938443672"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_NoMT[0].get_data().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 739 events and 141 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "83.5072706155633"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_FREEFORM[0].get_data().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 965 events and 141 original time points ...\n",
      "Using data from preloaded Raw for 960 events and 141 original time points ...\n",
      "1 bad epochs dropped\n",
      "Using data from preloaded Raw for 963 events and 141 original time points ...\n",
      "1 bad epochs dropped\n",
      "Using data from preloaded Raw for 968 events and 141 original time points ...\n",
      "1 bad epochs dropped\n",
      "Using data from preloaded Raw for 968 events and 141 original time points ...\n",
      "1 bad epochs dropped\n",
      "Using data from preloaded Raw for 968 events and 141 original time points ...\n",
      "1 bad epochs dropped\n",
      "Using data from preloaded Raw for 967 events and 141 original time points ...\n",
      "1 bad epochs dropped\n",
      "Using data from preloaded Raw for 739 events and 141 original time points ...\n",
      "Using data from preloaded Raw for 688 events and 141 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 700 events and 141 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 159 events and 141 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 157 events and 141 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 158 events and 141 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 159 events and 141 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 159 events and 141 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 163 events and 141 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 159 events and 141 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "epochs_data_NOMT = [file.get_data() for file in epochs_NoMT]\n",
    "epochs_data_FREEFORM = [file.get_data() for file in epochs_FREEFORM]\n",
    "epochs_Data_NOMT_2 = [file.get_data() for file in epochs_NOMT_only_code_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stacked_NOMT = np.vstack(epochs_data_NOMT)\n",
    "stacked_FREEFORM = np.vstack(epochs_data_FREEFORM)\n",
    "stacked_NOMT_2 = np.vstack(epochs_Data_NOMT_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6753, 21, 141)\n",
      "(2127, 21, 141)\n",
      "(1114, 21, 141)\n"
     ]
    }
   ],
   "source": [
    "print(stacked_NOMT.shape)\n",
    "print(stacked_FREEFORM.shape)\n",
    "print(stacked_NOMT_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "#\n",
    "# plt.hist(stacked_NOMT.reshape(-1), bins=np.arange(-25, 25), density=True)\n",
    "# plt.hist(stacked_FREEFORM.reshape(-1), bins=np.arange(-25, 25), density=True)\n",
    "# #plt.hist(stacked_NOMT_2.reshape(-1), bins=np.arange(-25,25),density=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(stacked_NOMT)\n",
    "np.random.shuffle(stacked_FREEFORM)\n",
    "np.random.shuffle(stacked_NOMT_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_nomt_train = stacked_NOMT[:5000]\n",
    "X_nomt_test = stacked_NOMT[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_free = stacked_FREEFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_nomt_2 = stacked_NOMT_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make Freeform test set same length as NoMT\n",
    "idy = random.sample(range(0, len(X_free)), X_nomt_test.shape[0])\n",
    "X_free_test = X_free[idy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 21, 141)\n",
      "(1753, 21, 141)\n",
      "(1753, 21, 141)\n",
      "(1114, 21, 141)\n"
     ]
    }
   ],
   "source": [
    "print(X_nomt_train.shape)\n",
    "print(X_nomt_test.shape)\n",
    "print(X_free_test.shape)\n",
    "print(X_nomt_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(a, b, th):\n",
    "    first = [1 if i < th else 0 for i in a]\n",
    "    last = [1 if i > th else 0 for i in b]\n",
    "    return sum(first + last) / len(first + last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calc_reconstruction_error(ae, A, B):\n",
    "    err = []\n",
    "    err2 = []\n",
    "    for i in A:\n",
    "        # need to expand here because the flatten layer assumes that the first dimension is the number of samples\n",
    "        i = np.expand_dims(i, axis=0)\n",
    "        err.append((np.square(i - ae.call(i))).mean())\n",
    "    print(\"###################\")\n",
    "\n",
    "    for j in B:\n",
    "        j = np.expand_dims(j, axis=0)\n",
    "        err2.append((np.square(j - ae.call(j))).mean())\n",
    "    print(\"##############\")\n",
    "    print(np.array(err).mean())\n",
    "    print(np.array(err2).mean())\n",
    "    return err, err2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Standard Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ -1.05243902  -1.00339141   0.74470383 ...  -6.89053426  -5.99624855\n",
      "    -5.30005807]\n",
      "  [ -4.25609756  -5.85704994  -3.9389547  ... -13.3841928  -13.06990708\n",
      "   -13.69371661]\n",
      "  [  2.19780488   1.8068525    1.57494774 ...  -3.30029036   3.50399535\n",
      "    -0.93981417]\n",
      "  ...\n",
      "  [ -0.83195122  -1.8529036   -0.73480836 ...  -6.71004646  -5.75576074\n",
      "    -5.93957027]\n",
      "  [ -4.5404878   -4.62144019  -6.53334495 ...  -2.44858304  -1.09429733\n",
      "    -0.25810685]\n",
      "  [  0.15512195   2.02416957  -1.53773519 ...   1.34702671   1.96131243\n",
      "     1.9175029 ]]\n",
      "\n",
      " [[  5.06401858  -1.32455285 -13.53455285 ... -13.9869338   -3.03312427\n",
      "    -5.75074332]\n",
      "  [ -0.53159117   3.2198374    0.3298374  ...  -9.04254355  -9.17873403\n",
      "   -13.72635308]\n",
      "  [ -2.88890825  -2.21747967   0.99252033 ...   2.63013937  -0.1760511\n",
      "     4.13632985]\n",
      "  ...\n",
      "  [ -1.58183508  -3.9504065   -3.2404065  ...  -6.29278746  -6.48897793\n",
      "    -7.57659698]\n",
      "  [ -3.30012776  -2.00869919  -2.32869919 ...  -5.97108014  -7.94727062\n",
      "    -8.96488966]\n",
      "  [ -2.16671312  -1.41528455  -0.39528455 ...   3.12233449   0.53614402\n",
      "    -0.56147503]]\n",
      "\n",
      " [[  4.91363531   1.68934959 -12.93303136 ... -13.70731707 -13.45779326\n",
      "     2.11173055]\n",
      "  [ -5.90173055 -12.46601626  -2.44839721 ... -13.65268293 -16.78315912\n",
      "    -9.78363531]\n",
      "  [  1.71900116 -12.62528455  -7.90766551 ...  -4.06195122   4.94757259\n",
      "     1.2470964 ]\n",
      "  ...\n",
      "  [ -2.83636469  -3.62065041  -1.25303136 ...  -4.46731707   1.41220674\n",
      "    -0.94826945]\n",
      "  [ -1.65392567  -1.40821138  -0.63059233 ...   4.53512195   5.97464576\n",
      "     2.33416957]\n",
      "  [  3.26192799   7.64764228   4.52526132 ...   2.68097561   2.21049942\n",
      "     1.45002323]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ -2.8324971   -8.05963995  -7.39630662 ...   3.982741     1.34512195\n",
      "    -0.93583043]\n",
      "  [ -4.32908246  -6.51622532  -4.73289199 ...  -7.10384437  -3.96146341\n",
      "    -2.5324158 ]\n",
      "  [  1.84969803  -0.22744483   0.4558885  ...  -4.20506388  -0.70268293\n",
      "    -1.65363531]\n",
      "  ...\n",
      "  [  0.11335656  -1.6937863   -2.40045296 ...  -4.01140534  -4.03902439\n",
      "    -3.50997677]\n",
      "  [  7.04042973   7.53328688   7.02662021 ...   0.38566783  -0.33195122\n",
      "    -0.1829036 ]\n",
      "  [  6.88994193   7.70279907   6.6961324  ...   3.47518002   3.84756098\n",
      "     3.61660859]]\n",
      "\n",
      " [[  2.70576074   1.64337979   4.07766551 ...  -2.69138211  -1.06995354\n",
      "    -2.28423926]\n",
      "  [ -0.34326365  -3.7056446    1.73864111 ...  -2.6204065   -5.83897793\n",
      "    -8.11326365]\n",
      "  [  1.60966318  -0.29271777   3.62156794 ...   1.43252033   2.7139489\n",
      "     0.37966318]\n",
      "  ...\n",
      "  [  2.09015099   2.16777003   4.54205575 ...  -0.95699187  -0.3555633\n",
      "    -0.80984901]\n",
      "  [  0.25722416   1.39484321   1.16912892 ...   0.8600813    1.74150987\n",
      "     2.72722416]\n",
      "  [ -1.10399535   0.75362369  -0.90209059 ...   0.46886179   2.71029036\n",
      "     4.87600465]]\n",
      "\n",
      " [[  3.25275261  -1.54105691  -8.72962834 ...   1.22799071   5.36608595\n",
      "    11.7384669 ]\n",
      "  [  3.35250871  -2.54130081  -5.59987224 ...  -0.91225319  -8.68415796\n",
      "     9.608223  ]\n",
      "  [ -5.73724739  -1.14105691   2.01037166 ...   0.99799071   7.80608595\n",
      "     5.7584669 ]\n",
      "  ...\n",
      "  [ -5.06919861  -2.52300813  -3.09157956 ...   1.54603949   2.98413473\n",
      "     2.67651568]\n",
      "  [ -9.43554007  -7.68934959  -5.16792102 ...  -1.82030197  -1.51220674\n",
      "    -4.99982578]\n",
      "  [ -4.03554007  -2.39934959   1.07207898 ...  -6.03030197  -6.48220674\n",
      "   -11.21982578]]]\n",
      "747.3898838559813\n",
      "153.28042973286878\n",
      "48.96082\n",
      "23.772148\n"
     ]
    }
   ],
   "source": [
    "norm_layer_nomt = layers.Normalization()\n",
    "norm_layer_free = layers.Normalization()\n",
    "norm_layer_nomt_2 = layers.Normalization()\n",
    "\n",
    "norm_layer_nomt.adapt(X_nomt_train.astype(float))\n",
    "norm_layer_free.adapt(X_free_test.astype(float))\n",
    "norm_layer_nomt_2.adapt(X_nomt_2.astype(float))\n",
    "\n",
    "print(X_nomt_train)\n",
    "print(np.max(X_nomt_train))\n",
    "print(np.max(X_free_test))\n",
    "print(np.max(norm_layer_nomt(X_nomt_train)))\n",
    "print(np.max(norm_layer_free(X_free_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scaled_X_nomt_train = norm_layer_nomt(X_nomt_train)\n",
    "scaled_X_nomt_test = norm_layer_nomt(X_nomt_test)\n",
    "scaled_X_free = norm_layer_free(X_free_test)\n",
    "scaled_X_nomt_2 = norm_layer_nomt_2(X_nomt_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "\n",
    "class Autoencoder(Model):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(1024, activation='gelu'),\n",
    "            layers.Dense(512, activation='gelu'),\n",
    "            layers.Dense(64, activation='gelu'),\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Dense(512, activation='gelu'),\n",
    "            layers.Dense(1024, activation='gelu'),\n",
    "            layers.Dense(21 * 141, activation='linear'),\n",
    "            layers.Reshape((21, 141))\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "autoencoder = Autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 3s 29ms/step - loss: 0.5941 - val_loss: 0.5534\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.4914 - val_loss: 0.4680\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.4545 - val_loss: 0.4828\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.4030 - val_loss: 0.4221\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 0.4210 - val_loss: 0.4616\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 0.4360 - val_loss: 0.4831\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 0.3996 - val_loss: 0.4256\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 0.3789 - val_loss: 0.4395\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 2s 28ms/step - loss: 0.3816 - val_loss: 0.3929\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 2s 28ms/step - loss: 0.3629 - val_loss: 0.4131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x170456dbd08>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "autoencoder.compile(optimizer=opt, loss=losses.MeanSquaredError())\n",
    "autoencoder.fit(scaled_X_nomt_train, scaled_X_nomt_train,\n",
    "                epochs=10,\n",
    "                batch_size=64,\n",
    "                shuffle=True,\n",
    "                validation_data=(scaled_X_nomt_test[:1000], scaled_X_nomt_test[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################\n",
      "##############\n",
      "0.388851\n",
      "0.6554856\n",
      "###################\n",
      "##############\n",
      "0.388851\n",
      "0.41024154\n"
     ]
    }
   ],
   "source": [
    "test_error,freeform_error=calc_reconstruction_error(autoencoder, scaled_X_nomt_test, scaled_X_free)\n",
    "test_error_1, test_error_2 = calc_reconstruction_error(autoencoder, scaled_X_nomt_test, scaled_X_nomt_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7635482030804336\n",
      "0.5755144750610394\n"
     ]
    }
   ],
   "source": [
    "print(calc_accuracy(test_error, freeform_error, np.mean([np.array(test_error).mean(), np.array(freeform_error).mean()])))\n",
    "print(calc_accuracy(test_error_1, test_error_2, np.mean([np.array(test_error_1).mean(), np.array(test_error_2).mean()])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5022818026240731"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_accuracy(test_error, freeform_error, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 141, 21)\n",
      "(1753, 141, 21)\n",
      "(1753, 141, 21)\n",
      "(1114, 141, 21)\n"
     ]
    }
   ],
   "source": [
    "X_nomt_train = np.moveaxis(X_nomt_train, 1, 2)\n",
    "X_nomt_test = np.moveaxis(X_nomt_test, 1, 2)\n",
    "X_free_test = np.moveaxis(X_free_test, 1, 2)\n",
    "X_nomt_2 = np.moveaxis(X_nomt_2, 1, 2)\n",
    "print(X_nomt_train.shape)\n",
    "print(X_nomt_test.shape)\n",
    "print(X_free_test.shape)\n",
    "print(X_nomt_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-5.14212544e+00 -1.00206620e+01  5.80714286e+00 ...  1.99885017e+00\n",
      "    3.98982578e+00  6.44031359e+00]\n",
      "  [-8.47926829e+00 -6.29780488e+00 -1.41000000e+00 ...  7.11707317e-01\n",
      "    4.51268293e+00  8.73317073e+00]\n",
      "  [ 1.02840650e+01  2.43552846e+00  1.62333333e+00 ...  1.13504065e+00\n",
      "    2.66601626e+00  4.49650407e+00]\n",
      "  ...\n",
      "  [-1.00240302e+01  3.59743322e+00  1.69523810e+00 ...  5.63694541e+00\n",
      "    3.15792102e+00  3.38408827e-01]\n",
      "  [ 4.24501742e+00  9.67648084e+00  5.34428571e+00 ...  5.28599303e+00\n",
      "    1.57696864e+00 -7.42543554e-01]\n",
      "  [ 1.18354936e+01  4.06695703e+00  2.34761905e-01 ...  4.12646922e+00\n",
      "   -1.11255517e+00 -7.82067364e-01]]\n",
      "\n",
      " [[-1.78118467e+00 -2.76459930e+00 -9.50452962e-01 ... -3.34728223e+00\n",
      "    8.64668990e-01  5.32418118e+00]\n",
      "  [-1.64518002e-01 -6.97932636e-01  1.82621370e+00 ... -8.50615563e-01\n",
      "    1.34133566e+00  4.50847851e-01]\n",
      "  [-4.26898955e-01 -1.46031359e+00  2.56383275e+00 ... -8.82996516e-01\n",
      "    2.59895470e+00 -1.15331010e-02]\n",
      "  ...\n",
      "  [ 8.04976771e+00  1.10263531e+01 -3.83950058e+00 ...  3.69367015e+00\n",
      "   -1.27543786e+01  1.67151336e+01]\n",
      "  [ 8.22072009e+00  1.04573055e+01 -5.36854820e+00 ...  4.27462253e+00\n",
      "   -1.25234262e+01  1.89060859e+01]\n",
      "  [ 7.83976771e+00  1.14463531e+01 -5.80950058e+00 ...  4.37367015e+00\n",
      "   -1.35243786e+01  1.86051336e+01]]\n",
      "\n",
      " [[-3.44469222e+00  3.67579559e+00  7.03262485e+00 ...  1.88823461e+00\n",
      "   -6.76469222e+00 -1.05566783e+00]\n",
      "  [-9.07612079e+00  1.56436702e+00  9.50119628e+00 ...  4.96806039e-01\n",
      "   -6.15612079e+00  1.22290360e+00]\n",
      "  [-2.23251684e+01 -1.51468060e+00  9.84214866e+00 ... -1.08224158e+00\n",
      "   -6.50516841e+00  2.09385598e+00]\n",
      "  ...\n",
      "  [-2.92278746e+00  3.23770035e+00  2.38452962e+00 ...  1.70139373e-01\n",
      "   -4.43278746e+00  8.06236934e-01]\n",
      "  [ 1.11914983e+01  1.70198606e+00  6.53881533e+00 ...  1.24442509e+00\n",
      "   -4.31850174e+00 -8.89477352e-01]\n",
      "  [ 2.70586411e+01  3.64912892e+00 -2.23404181e+00 ... -1.59843206e+00\n",
      "   -4.64135889e+00 -3.36233449e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-2.11765389e+00  4.13063879e+00 -7.39009292e+00 ... -2.41399535e+00\n",
      "   -3.83301974e+00 -7.18155633e+00]\n",
      "  [ 5.63186992e+00  9.21016260e+00  5.49430894e-01 ...  1.67552846e+00\n",
      "   -5.49349593e+00 -7.82203252e+00]\n",
      "  [ 1.10139373e+00  3.78968641e+00 -5.08104530e+00 ... -3.24947735e-01\n",
      "   -5.52397213e+00 -5.02250871e+00]\n",
      "  ...\n",
      "  [-1.27238444e+01 -1.78255517e+01 -5.68628339e+00 ... -1.28101858e+01\n",
      "   -5.39210221e-01  1.26322532e+01]\n",
      "  [-1.47795587e+01 -1.36812660e+01 -7.32199768e+00 ... -1.17259001e+01\n",
      "   -9.74924506e-01  1.33665389e+01]\n",
      "  [-1.29514634e+01 -1.21331707e+01 -8.50390244e+00 ... -6.83780488e+00\n",
      "    2.80317073e+00  1.26246341e+01]]\n",
      "\n",
      " [[-4.03948897e-02  5.06277584e+00  3.99984901e+00 ... -4.78931475e-01\n",
      "    2.32228804e+00 -3.09649245e+00]\n",
      "  [ 8.45389082e+00  2.57706156e+00  5.75413473e+00 ...  4.05354239e-01\n",
      "    3.74657375e+00 -6.92206736e-01]\n",
      "  [ 1.19105575e+01  2.24372822e+00 -2.87919861e+00 ... -2.24797909e+00\n",
      "    3.34324042e+00  3.11445993e+00]\n",
      "  ...\n",
      "  [-2.42277584e+00  3.12039489e+00  2.20774681e+01 ...  2.01886876e+01\n",
      "    9.92990708e+00 -1.93887340e+00]\n",
      "  [ 5.78176539e-01  9.71347271e-01  1.01384204e+01 ...  1.77896400e+01\n",
      "    1.02008595e+01 -8.77921022e-01]\n",
      "  [ 1.44157956e+01  2.17896632e+00  1.69260395e+01 ...  2.01572590e+01\n",
      "    1.23684785e+01 -1.74030197e+00]]\n",
      "\n",
      " [[ 6.12816492e+00 -3.47476190e+00  1.86459698e+01 ...  3.20523810e+00\n",
      "    1.43938444e+00 -4.03298490e-01]\n",
      "  [ 7.33768873e+00  2.56476190e+00  3.16549361e+00 ...  2.68476190e+00\n",
      "    6.88908246e-01 -6.73774681e-01]\n",
      "  [-3.13278746e+00  2.20428571e+00  4.41501742e+00 ...  2.98428571e+00\n",
      "    1.07843206e+00  1.45749129e-01]\n",
      "  ...\n",
      "  [-3.94541231e-02  8.75761905e+00  2.63835075e+00 ...  2.75761905e+00\n",
      "    2.13176539e+00 -1.59091754e+00]\n",
      "  [ 1.51267364e+01  2.24838095e+01  1.00454123e+00 ...  1.20380952e+00\n",
      "   -1.63204413e+00 -2.68472706e+00]\n",
      "  [ 2.27534030e+01  1.80204762e+01  3.78120790e+00 ... -1.80952381e+00\n",
      "   -6.95537747e+00 -4.24806039e+00]]]\n",
      "865.3172938443672\n",
      "153.28042973286878\n",
      "67.54036\n",
      "13.497336\n"
     ]
    }
   ],
   "source": [
    "norm_layer_nomt = layers.Normalization()\n",
    "norm_layer_free = layers.Normalization()\n",
    "norm_layer_nomt_2 = layers.Normalization()\n",
    "\n",
    "norm_layer_nomt.adapt(X_nomt_train.astype(float))\n",
    "norm_layer_free.adapt(X_free_test.astype(float))\n",
    "norm_layer_nomt_2.adapt(X_nomt_2.astype(float))\n",
    "\n",
    "print(X_nomt_train)\n",
    "print(np.max(X_nomt_train))\n",
    "print(np.max(X_free_test))\n",
    "print(np.max(norm_layer_nomt(X_nomt_train)))\n",
    "print(np.max(norm_layer_free(X_free_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scaled_X_nomt_train = norm_layer_nomt(X_nomt_train)\n",
    "scaled_X_nomt_test = norm_layer_nomt(X_nomt_test)\n",
    "scaled_X_free = norm_layer_free(X_free_test)\n",
    "scaled_X_nomt_2 = norm_layer_nomt_2(X_nomt_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "encoding_dim = 50\n",
    "\n",
    "class ConvAutoencoder(Model):\n",
    "    def __init__(self, encoding_dim):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Input(shape=(X_nomt_train.shape[1], X_nomt_train.shape[2])),  # 141, 21\n",
    "            layers.Conv1D(42, 3, activation=None, padding='same'),\n",
    "            layers.LeakyReLU(),\n",
    "            layers.MaxPooling1D(pool_size=2, padding=\"same\"),\n",
    "            layers.Conv1D(84, 3, activation=None, padding='same'),\n",
    "            layers.LeakyReLU(),\n",
    "            layers.MaxPooling1D(pool_size=2, padding=\"same\"),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(encoding_dim, activation=\"relu\")\n",
    "        ])\n",
    "\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Dense(36*84, activation=\"relu\", use_bias=False),\n",
    "            layers.Reshape((36, 84)),\n",
    "            layers.Conv1DTranspose(84, kernel_size=3, activation=None, padding='same'),\n",
    "            layers.LeakyReLU(),\n",
    "            layers.UpSampling1D(),\n",
    "            layers.Conv1DTranspose(42, kernel_size=3, activation=None, padding='same'),\n",
    "            layers.LeakyReLU(),\n",
    "            layers.UpSampling1D(),\n",
    "            layers.Conv1D(X_nomt_train.shape[2], kernel_size=3, activation=None, padding='same'),\n",
    "            layers.Cropping1D(cropping=(2,1))\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "conv_autoencoder = ConvAutoencoder(encoding_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "conv_autoencoder.compile(optimizer=opt, loss=losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "af0ab5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 141, 42)           2688      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 141, 42)           0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 71, 42)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 71, 84)            10668     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 71, 84)            0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 36, 84)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                151250    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164,606\n",
      "Trainable params: 164,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_autoencoder.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2428e7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_autoencoder.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 3s 28ms/step - loss: 0.7464 - val_loss: 0.4922\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 0.5063 - val_loss: 0.4585\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.4638 - val_loss: 0.3975\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 0.3952 - val_loss: 0.3529\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 0.3627 - val_loss: 0.3324\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 0.3408 - val_loss: 0.3205\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 0.3450 - val_loss: 0.3058\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 0.3221 - val_loss: 0.3010\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 0.3213 - val_loss: 0.3006\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 0.3129 - val_loss: 0.3006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e6b1749cc8>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_autoencoder.fit(scaled_X_nomt_train, scaled_X_nomt_train,\n",
    "                     epochs=10,\n",
    "                     batch_size=64,\n",
    "                     shuffle=True,\n",
    "                     validation_data=(scaled_X_nomt_test, scaled_X_nomt_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################\n",
      "##############\n",
      "0.30056337\n",
      "0.54203016\n",
      "###################\n",
      "##############\n",
      "0.30056337\n",
      "0.33237106\n"
     ]
    }
   ],
   "source": [
    "test_error, freeform_error = calc_reconstruction_error(conv_autoencoder, scaled_X_nomt_test, scaled_X_free)\n",
    "# test_error_1, test_error_2 = calc_reconstruction_error(conv_autoencoder, scaled_X_nomt_test, scaled_X_nomt_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8200228180262408\n",
      "0.5493547261946286\n"
     ]
    }
   ],
   "source": [
    "print(calc_accuracy(test_error, freeform_error, np.mean([np.array(test_error).mean(), np.array(freeform_error).mean()])))\n",
    "# print(calc_accuracy(test_error_1, test_error_2, np.mean([np.array(test_error_1).mean(), np.array(test_error_2).mean()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4982886480319452"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_accuracy(test_error, freeform_error, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79b72e98",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder - Variants\n",
    "## Increased encoding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conv_autoencoder = ConvAutoencoder(encoding_dim=256)\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "conv_autoencoder.compile(optimizer=opt, loss=losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2a05706a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 3s 29ms/step - loss: 0.6017 - val_loss: 0.4228\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 2s 28ms/step - loss: 0.4334 - val_loss: 0.3878\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.3989 - val_loss: 0.3760\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 2s 28ms/step - loss: 0.3659 - val_loss: 0.3447\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 2s 28ms/step - loss: 0.3394 - val_loss: 0.2955\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.3065 - val_loss: 0.3252\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.3105 - val_loss: 0.2928\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 2s 28ms/step - loss: 0.3020 - val_loss: 0.2732\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 2s 28ms/step - loss: 0.2864 - val_loss: 0.2671\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 2s 28ms/step - loss: 0.2759 - val_loss: 0.2598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e6cbc030c8>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_autoencoder.fit(scaled_X_nomt_train, scaled_X_nomt_train,\n",
    "                     epochs=10,\n",
    "                     batch_size=64,\n",
    "                     shuffle=True,\n",
    "                     validation_data=(scaled_X_nomt_test, scaled_X_nomt_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9d556e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################\n",
      "##############\n",
      "0.25977543\n",
      "0.4511026\n"
     ]
    }
   ],
   "source": [
    "test_error, freeform_error = calc_reconstruction_error(conv_autoencoder, scaled_X_nomt_test, scaled_X_free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9aa14e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8034797490017114\n"
     ]
    }
   ],
   "source": [
    "print(calc_accuracy(test_error, freeform_error, np.mean([np.array(test_error).mean(), np.array(freeform_error).mean()])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16b69881",
   "metadata": {},
   "source": [
    "## More layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "279d9922",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "encoding_dim = 50\n",
    "\n",
    "class ConvAutoencoder(Model):\n",
    "    def __init__(self, encoding_dim):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Input(shape=(X_nomt_train.shape[1], X_nomt_train.shape[2])),  # 141, 21\n",
    "            layers.Conv1D(42, 3, activation=None, padding='same'),\n",
    "            layers.LeakyReLU(),\n",
    "            layers.MaxPooling1D(pool_size=2, padding=\"same\"),\n",
    "            layers.Conv1D(84, 3, activation=None, padding='same'),\n",
    "            layers.LeakyReLU(),\n",
    "            layers.MaxPooling1D(pool_size=2, padding=\"same\"),\n",
    "            layers.Conv1D(168, 3, activation=None, padding='same'),\n",
    "            layers.LeakyReLU(),\n",
    "            layers.MaxPooling1D(pool_size=2, padding=\"same\"),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(encoding_dim, activation=\"relu\")\n",
    "        ])\n",
    "\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Dense(18*168, activation=\"relu\", use_bias=False),\n",
    "            layers.Reshape((18, 168)),\n",
    "            layers.Conv1DTranspose(168, kernel_size=3, activation=None, padding='same'),\n",
    "            layers.LeakyReLU(),\n",
    "            layers.UpSampling1D(),\n",
    "            layers.Conv1DTranspose(84, kernel_size=3, activation=None, padding='same'),\n",
    "            layers.LeakyReLU(),\n",
    "            layers.UpSampling1D(),\n",
    "            layers.Conv1DTranspose(42, kernel_size=3, activation=None, padding='same'),\n",
    "            layers.LeakyReLU(),\n",
    "            layers.UpSampling1D(),\n",
    "            layers.Conv1D(X_nomt_train.shape[2], kernel_size=3, activation=None, padding='same'),\n",
    "            layers.Cropping1D(cropping=(2,1))\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "conv_autoencoder = ConvAutoencoder(encoding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cdf4e83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "conv_autoencoder.compile(optimizer=opt, loss=losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c0e1fb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 141, 42)           2688      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 141, 42)           0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 71, 42)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 71, 84)            10668     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 71, 84)            0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 36, 84)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 36, 168)           42504     \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 36, 168)           0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 18, 168)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                151250    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 207,110\n",
      "Trainable params: 207,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_autoencoder.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ce0bc17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 4s 35ms/step - loss: 0.8651 - val_loss: 0.6083\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 2s 31ms/step - loss: 0.6030 - val_loss: 0.5298\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 2s 31ms/step - loss: 0.5463 - val_loss: 0.4833\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 2s 32ms/step - loss: 0.5028 - val_loss: 0.4519\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 2s 32ms/step - loss: 0.4810 - val_loss: 0.4379\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 2s 31ms/step - loss: 0.4567 - val_loss: 0.4166\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 3s 32ms/step - loss: 0.4315 - val_loss: 0.3927\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 2s 31ms/step - loss: 0.4140 - val_loss: 0.3825\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 2s 31ms/step - loss: 0.4031 - val_loss: 0.3732\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 3s 32ms/step - loss: 0.3895 - val_loss: 0.3714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e6c5ba0b08>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_autoencoder.fit(scaled_X_nomt_train, scaled_X_nomt_train,\n",
    "                     epochs=10,\n",
    "                     batch_size=64,\n",
    "                     shuffle=True,\n",
    "                     validation_data=(scaled_X_nomt_test, scaled_X_nomt_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5b60aa20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################\n",
      "##############\n",
      "0.37138057\n",
      "0.6604081\n"
     ]
    }
   ],
   "source": [
    "test_error, freeform_error = calc_reconstruction_error(conv_autoencoder, scaled_X_nomt_test, scaled_X_free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ebdf315f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8054763262977752\n"
     ]
    }
   ],
   "source": [
    "print(calc_accuracy(test_error, freeform_error, np.mean([np.array(test_error).mean(), np.array(freeform_error).mean()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cdd272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aa137f996c322d810b0ba78b9855db9c260b81f9ff796e150df9906e831bb7ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
