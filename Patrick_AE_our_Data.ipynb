{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    import PyQt5.QtCore\n",
    "    %matplotlib qt\n",
    "except ImportError:\n",
    "    %matplotlib inline\n",
    "import keras\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "from mne.channels import make_standard_montage\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data_dir = os.path.dirname(\"./data/\")\n",
    "data_files = os.listdir(data_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def annotations_from_eGUI(raw, egui):\n",
    "    codes = []\n",
    "    starts = []\n",
    "\n",
    "    current_state = None\n",
    "\n",
    "    for i in range(len(egui)):\n",
    "        if egui[i][0] != current_state:\n",
    "            starts.append(i)\n",
    "            current_state = egui[i][0]\n",
    "            codes.append(str(egui[i][0]))\n",
    "\n",
    "    starts.append(len(egui))\n",
    "    codes = np.array(codes)\n",
    "    sf = raw.info.get('sfreq')\n",
    "    starts = np.array(starts) / sf\n",
    "    durations = starts[1:] - starts[:-1]\n",
    "    starts = starts[:-1]\n",
    "\n",
    "    raw.set_annotations(mne.Annotations(onset=starts, duration=durations, description=codes))\n",
    "\n",
    "\n",
    "def raw_from_mat(file):\n",
    "    mat = loadmat(os.path.join(data_dir, file))\n",
    "\n",
    "    sampling_freq = mat[\"o\"][0][0][2][0][0]\n",
    "    n_samples = mat[\"o\"][0][0][3][0][0]\n",
    "    ch_names = [element[0][0] for element in mat[\"o\"][0][0][6]]\n",
    "\n",
    "    df = pd.DataFrame(mat[\"o\"][0][0][5], columns=ch_names)\n",
    "    df = df.drop(columns=[\"X5\"])\n",
    "    df = df.T\n",
    "    ch_names.remove(\"X5\")\n",
    "\n",
    "    ch_types = ['eeg'] * 21\n",
    "    info = mne.create_info(ch_names, ch_types=ch_types, sfreq=sampling_freq)\n",
    "    raw = mne.io.RawArray(df.to_numpy(), info)\n",
    "\n",
    "    montage = make_standard_montage(\"standard_prefixed\")\n",
    "    raw.set_montage(montage)\n",
    "\n",
    "    raw.load_data().set_eeg_reference(ref_channels='average')\n",
    "    annotations_from_eGUI(raw, mat[\"o\"][0][0][4])\n",
    "    return raw\n",
    "\n",
    "\n",
    "def filter_raw(raw):\n",
    "    return raw.load_data().filter(0.1, 30, method=\"fir\", phase=\"zero-double\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=21, n_times=664400\n",
      "    Range : 0 ... 664399 =      0.000 ...  3321.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=664600\n",
      "    Range : 0 ... 664599 =      0.000 ...  3322.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=662400\n",
      "    Range : 0 ... 662399 =      0.000 ...  3311.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=667600\n",
      "    Range : 0 ... 667599 =      0.000 ...  3337.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=734400\n",
      "    Range : 0 ... 734399 =      0.000 ...  3671.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=667000\n",
      "    Range : 0 ... 666999 =      0.000 ...  3334.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=678400\n",
      "    Range : 0 ... 678399 =      0.000 ...  3391.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=475000\n",
      "    Range : 0 ... 474999 =      0.000 ...  2374.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=391800\n",
      "    Range : 0 ... 391799 =      0.000 ...  1958.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=285800\n",
      "    Range : 0 ... 285799 =      0.000 ...  1428.995 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n"
     ]
    }
   ],
   "source": [
    "raw_NoMT = [raw_from_mat(file) for file in data_files if \"NoMT\" in file]\n",
    "raw_FREEFORM = [raw_from_mat(file) for file in data_files if \"FREEFORM\" in file]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_epochs(raw):\n",
    "    metadata_tmin, metadata_tmax = -1, 1\n",
    "\n",
    "    all_events, all_event_id = mne.events_from_annotations(raw)\n",
    "    metadata, events, event_id = mne.epochs.make_metadata(\n",
    "        events=all_events,\n",
    "        event_id=all_event_id,\n",
    "        tmin=metadata_tmin,\n",
    "        tmax=metadata_tmax,\n",
    "        sfreq=raw.info[\"sfreq\"],\n",
    "    )\n",
    "    return mne.Epochs(raw, events, event_id, reject_by_annotation=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1931 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1919 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1925 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1935 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1935 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1935 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1933 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '99']\n",
      "Not setting metadata\n",
      "1481 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '99']\n",
      "Not setting metadata\n",
      "1383 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '99']\n",
      "Not setting metadata\n",
      "1409 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "epochs_NoMT = [get_epochs(file) for file in raw_NoMT]\n",
    "epochs_FREEFORM = [get_epochs(file) for file in raw_FREEFORM]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1931 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1919 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1925 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1935 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1935 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1935 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '3', '4', '5', '6', '91', '92', '99']\n",
      "Not setting metadata\n",
      "1933 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '99']\n",
      "Not setting metadata\n",
      "1481 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '99']\n",
      "Not setting metadata\n",
      "1383 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: ['0', '1', '2', '99']\n",
      "Not setting metadata\n",
      "1409 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "epochs_NoMT = [get_epochs(file) for file in raw_NoMT]\n",
    "epochs_FREEFORM = [get_epochs(file) for file in raw_FREEFORM]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 1931 events and 141 original time points ...\n",
      "1 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/plain": "865.3172938443672"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_NoMT[0].get_data().max()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 1481 events and 141 original time points ...\n",
      "1 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/plain": "158.92792102206735"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_FREEFORM[0].get_data().max()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 1930 events and 141 original time points ...\n",
      "Using data from preloaded Raw for 1919 events and 141 original time points ...\n",
      "1 bad epochs dropped\n",
      "Using data from preloaded Raw for 1925 events and 141 original time points ...\n",
      "1 bad epochs dropped\n",
      "Using data from preloaded Raw for 1935 events and 141 original time points ...\n",
      "1 bad epochs dropped\n",
      "Using data from preloaded Raw for 1935 events and 141 original time points ...\n",
      "1 bad epochs dropped\n",
      "Using data from preloaded Raw for 1935 events and 141 original time points ...\n",
      "1 bad epochs dropped\n",
      "Using data from preloaded Raw for 1933 events and 141 original time points ...\n",
      "1 bad epochs dropped\n",
      "Using data from preloaded Raw for 1480 events and 141 original time points ...\n",
      "Using data from preloaded Raw for 1383 events and 141 original time points ...\n",
      "1 bad epochs dropped\n",
      "Using data from preloaded Raw for 1409 events and 141 original time points ...\n",
      "1 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "epochs_data_NOMT = [file.get_data() for file in epochs_NoMT]\n",
    "epochs_data_FREEFORM = [file.get_data() for file in epochs_FREEFORM]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "stacked_NOMT = np.vstack(epochs_data_NOMT)\n",
    "stacked_FREEFORM = np.vstack(epochs_data_FREEFORM)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(13506, 21, 141)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_NOMT.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(4270, 21, 141)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_FREEFORM.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "np.random.shuffle(stacked_NOMT)\n",
    "np.random.shuffle(stacked_FREEFORM)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "X_nomt_train = stacked_NOMT[:12000]\n",
    "X_nomt_test = stacked_NOMT[12000:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "X_free = stacked_FREEFORM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# make Freeform test set same length as NoMT\n",
    "idy = random.sample(range(0, len(X_free)), X_nomt_test.shape[0])\n",
    "X_free_test = X_free[idy]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "(1506, 21, 141)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_free_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-9.27270616e-01 -1.61774681e+00 -2.84679443e+00 ... -6.65965157e+00\n",
      "   -3.15774681e+00 -5.47393728e+00]\n",
      "  [-9.88483159e+00 -1.14553078e+01 -4.06435540e+00 ... -9.32721254e+00\n",
      "   -9.29530778e+00 -8.18149826e+00]\n",
      "  [ 7.62241580e-01 -7.78234611e-01 -8.87282230e-01 ...  9.29860627e-01\n",
      "    5.45176539e+00 -1.94442509e+00]\n",
      "  ...\n",
      "  [-1.00190476e+00 -2.23809524e-02 -1.63142857e+00 ... -3.92428571e+00\n",
      "   -1.78238095e+00 -4.91857143e+00]\n",
      "  [ 4.16387921e-01  9.45911731e-01  3.96864111e-01 ...  9.14006969e-01\n",
      "    7.95911731e-01  4.97212544e-02]\n",
      "  [ 1.29663182e+00  2.40615563e+00  1.66710801e+00 ...  6.53425087e+00\n",
      "    6.28615563e+00  8.12996516e+00]]\n",
      "\n",
      " [[ 3.35360046e+00  2.31026713e+00  8.69169570e+00 ... -5.73401858e+00\n",
      "   -2.73687573e+00 -6.93497096e+00]\n",
      "  [ 3.43600465e-01  1.23026713e+00  3.49169570e+00 ... -5.51401858e+00\n",
      "   -5.63687573e+00 -5.59497096e+00]\n",
      "  [-7.12009292e-01  1.47465738e+00 -8.73914053e-01 ... -6.80962834e+00\n",
      "   -7.59248548e+00 -7.18058072e+00]\n",
      "  ...\n",
      "  [ 9.70150987e-02 -3.06318235e-01  3.60511034e+00 ... -6.33060395e+00\n",
      "   -5.42346109e+00 -6.68155633e+00]\n",
      "  [-8.47957027e+00 -9.86290360e+00 -6.79147503e+00 ...  2.18281069e+00\n",
      "    2.44995354e+00  8.21858304e-01]\n",
      "  [ 1.51652729e+00  1.40319396e+00 -8.25377468e-01 ... -6.91091754e-01\n",
      "    1.34605110e+00  1.47955865e-01]]\n",
      "\n",
      " [[ 8.13356562e-01 -1.71196283e-02  4.40023229e-01 ... -2.96140534e+00\n",
      "   -5.46378630e+00 -5.80711963e+00]\n",
      "  [ 4.48722416e-01  7.38246225e-01  1.73538908e+00 ... -5.06603949e+00\n",
      "   -8.05842044e+00 -1.01517538e+01]\n",
      "  [-3.41615563e+00 -4.00663182e+00 -1.25948897e+00 ...  1.30908246e+00\n",
      "   -6.83298490e-01 -6.76631823e-01]\n",
      "  ...\n",
      "  [-1.21566783e+00 -1.32614402e+00 -1.00900116e+00 ... -6.28042973e+00\n",
      "   -7.32281069e+00 -7.21614402e+00]\n",
      "  [-2.15396051e+00 -2.51443670e+00 -3.79729384e+00 ... -8.10872242e+00\n",
      "   -5.04110337e+00 -1.24443670e+00]\n",
      "  [-2.32078978e+00 -1.65126597e+00 -1.66412311e+00 ... -2.15551684e-01\n",
      "    1.94206736e+00  4.14873403e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 5.15898955e+00 -3.49815331e+00 -1.14672474e+00 ...  1.40803717e+00\n",
      "    5.38422764e+00  2.97327526e+00]\n",
      "  [ 5.25264808e+00  4.17550523e+00 -1.40306620e+00 ...  7.27169570e+00\n",
      "    7.09788618e+00  6.49693380e+00]\n",
      "  [ 4.45484321e+00  1.97770035e+00  1.28912892e+00 ...  1.68389082e+00\n",
      "   -4.12991870e+00 -5.63087108e+00]\n",
      "  ...\n",
      "  [ 7.37801394e+00  5.98087108e+00  3.10229965e+00 ...  1.56706156e+00\n",
      "    1.73252033e-01 -2.52770035e+00]\n",
      "  [ 8.17526132e-01  1.45038328e+00  1.93181185e+00 ... -4.40342625e+00\n",
      "   -6.33723577e+00 -6.74818815e+00]\n",
      "  [-7.21254355e-01  1.59160279e+00  4.03303136e+00 ... -6.52220674e+00\n",
      "   -7.03601626e+00 -3.95696864e+00]]\n",
      "\n",
      " [[-5.18796748e+00  8.22869919e+00 -3.20463415e+00 ...  1.82044135e+01\n",
      "    8.41393728e+00  1.99610801e+01]\n",
      "  [ 5.70813008e-01  7.01747967e+00  1.63941463e+01 ...  1.89319396e+00\n",
      "    1.29627178e+01  2.45598606e+01]\n",
      "  [-1.57869919e+00 -1.72203252e+00 -6.72536585e+00 ... -7.17631823e+00\n",
      "   -9.36679443e+00 -9.95965157e+00]\n",
      "  ...\n",
      "  [-4.63869919e+00 -4.38203252e+00 -6.22536585e+00 ...  1.25368177e+00\n",
      "    4.09320557e+00  5.15034843e+00]\n",
      "  [-3.67943089e+00 -5.30276423e+00 -6.40609756e+00 ...  1.02295006e+00\n",
      "   -1.09752613e+00 -4.14038328e+00]\n",
      "  [ 2.54008130e+00  2.67479675e-02 -1.59658537e+00 ...  2.33246225e+00\n",
      "    1.35198606e+00 -2.88087108e+00]]\n",
      "\n",
      " [[-1.07465505e+01 -1.21127410e+01 -9.86178862e+00 ... -9.84922648e+01\n",
      "   -9.56246458e+01 -8.59870267e+01]\n",
      "  [-1.21397213e+01 -1.40559117e+01 -1.17149593e+01 ... -9.52454355e+01\n",
      "   -8.65178165e+01 -8.05001974e+01]\n",
      "  [ 3.49735192e+00  4.93116144e+00  7.33211382e+00 ... -3.94783624e+01\n",
      "   -3.67407433e+01 -3.49931243e+01]\n",
      "  ...\n",
      "  [ 3.72418118e+00  5.03799071e+00  6.94894309e+00 ... -3.56215331e+01\n",
      "   -3.34039141e+01 -3.20562950e+01]\n",
      "  [ 1.10417422e+01  1.36255517e+01  1.37265041e+01 ... -6.67397213e+00\n",
      "   -5.18635308e+00 -5.53873403e+00]\n",
      "  [ 4.23393728e+00  6.12774681e+00  7.78869919e+00 ... -2.45177700e+00\n",
      "   -3.42415796e+00 -6.95653891e+00]]]\n",
      "865.3172938443672\n",
      "158.92792102206735\n",
      "106.682144\n",
      "28.972511\n"
     ]
    }
   ],
   "source": [
    "layer = layers.Normalization()\n",
    "layer1 = layers.Normalization()\n",
    "layer.adapt(X_nomt_train.astype(float))\n",
    "layer1.adapt(X_free_test.astype(float))\n",
    "\n",
    "print(X_nomt_train)\n",
    "print(np.max(X_nomt_train))\n",
    "print(np.max(X_free_test))\n",
    "print(np.max(layer(X_nomt_train)))\n",
    "print(np.max(layer1(X_free_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def calc_accuracy(a, b, th):\n",
    "    first = [1 if i < th else 0 for i in a]\n",
    "    last = [1 if i > th else 0 for i in b]\n",
    "    return sum(first + last) / len(first + last)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Standard Autoencoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "latent_dim = 512\n",
    "keras.backend.clear_session()\n",
    "\n",
    "\n",
    "class Autoencoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(1024, activation='gelu'),\n",
    "            layers.Dense(512, activation='gelu'),\n",
    "            layers.Dense(64, activation='gelu'),\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Dense(512, activation='gelu'),\n",
    "            layers.Dense(1024, activation='gelu'),\n",
    "            layers.Dense(21 * 141, activation='linear'),\n",
    "            layers.Reshape((21, 141))\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "autoencoder = Autoencoder(latent_dim)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "188/188 [==============================] - 7s 26ms/step - loss: 0.5549 - val_loss: 0.4079\n",
      "Epoch 2/50\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.4655 - val_loss: 0.3988\n",
      "Epoch 3/50\n",
      "110/188 [================>.............] - ETA: 1s - loss: 0.3961"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_10144\\165942399.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m                 \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m64\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m                 \u001B[0mshuffle\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m                 validation_data=(layer(X_nomt_test[:1000]), layer(X_nomt_test[:1000])))\n\u001B[0m",
      "\u001B[1;32m~\\Documents\\GitHub\\Nueorinformatics_project\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     64\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 65\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     66\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     67\u001B[0m             \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\GitHub\\Nueorinformatics_project\\venv\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1648\u001B[0m                         ):\n\u001B[0;32m   1649\u001B[0m                             \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1650\u001B[1;33m                             \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1651\u001B[0m                             \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1652\u001B[0m                                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\GitHub\\Nueorinformatics_project\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    149\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 150\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    151\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\GitHub\\Nueorinformatics_project\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    878\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    879\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 880\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    881\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    882\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\GitHub\\Nueorinformatics_project\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    910\u001B[0m       \u001B[1;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    911\u001B[0m       \u001B[1;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 912\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_no_variable_creation_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=not-callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    913\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_variable_creation_fn\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    914\u001B[0m       \u001B[1;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\GitHub\\Nueorinformatics_project\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    133\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0;32m    134\u001B[0m     return concrete_function._call_flat(\n\u001B[1;32m--> 135\u001B[1;33m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0m\u001B[0;32m    136\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    137\u001B[0m   \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\GitHub\\Nueorinformatics_project\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1744\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1745\u001B[0m       return self._build_call_outputs(self._inference_function.call(\n\u001B[1;32m-> 1746\u001B[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0m\u001B[0;32m   1747\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001B[0;32m   1748\u001B[0m         \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\GitHub\\Nueorinformatics_project\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    381\u001B[0m               \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    382\u001B[0m               \u001B[0mattrs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mattrs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 383\u001B[1;33m               ctx=ctx)\n\u001B[0m\u001B[0;32m    384\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    385\u001B[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001B[1;32m~\\Documents\\GitHub\\Nueorinformatics_project\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     51\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     52\u001B[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[1;32m---> 53\u001B[1;33m                                         inputs, attrs, num_outputs)\n\u001B[0m\u001B[0;32m     54\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     55\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "autoencoder.compile(optimizer=opt, loss=losses.MeanSquaredError())\n",
    "autoencoder.fit(layer(X_nomt_train), layer(X_nomt_train),\n",
    "                epochs=50,\n",
    "                batch_size=64,\n",
    "                shuffle=True,\n",
    "                validation_data=(layer(X_nomt_test[:1000]), layer(X_nomt_test[:1000])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "err = []\n",
    "err2 = []\n",
    "for i in X_nomt_train:\n",
    "    # need to expand here because the flatten layer assumes that the first dimension is the number of samples\n",
    "    i = np.expand_dims(i, axis=0)\n",
    "    encoded = autoencoder.encoder(layer(i)).numpy()\n",
    "    decoded = autoencoder.decoder(encoded).numpy()\n",
    "    #print(\"Error:\",(np.square(i-decoded)).mean())\n",
    "    err.append((np.square(layer(i) - decoded)).mean())\n",
    "print(\"###################\")\n",
    "\n",
    "for j in X_free_test:\n",
    "    j = np.expand_dims(j, axis=0)\n",
    "    encoded = autoencoder.encoder(layer1(j)).numpy()\n",
    "    decoded = autoencoder.decoder(encoded).numpy()\n",
    "    #print(\"Error:\",(np.square(layer(j)-decoded)).mean())\n",
    "    err2.append((np.square(layer1(j) - decoded)).mean())\n",
    "print(\"##############\")\n",
    "print(np.array(err).mean())\n",
    "print(np.array(err2).mean())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "calc_accuracy(err, err2, np.mean([np.array(err).mean(), np.array(err2).mean()]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convolutional Autoencoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "(12000, 21, 141, 1)"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_nomt_train = X_nomt_train[..., np.newaxis]\n",
    "X_nomt_test = X_nomt_test[..., np.newaxis]\n",
    "X_free_test = X_free_test[..., np.newaxis]\n",
    "X_nomt_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "latent_dim = 512\n",
    "keras.backend.clear_session()\n",
    "\n",
    "\n",
    "class ConvAutoencoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Input(shape=(21, 141, 1)),\n",
    "            layers.Conv2D(16, (3, 3), activation='relu', padding='same', strides=2),\n",
    "            layers.Conv2D(8, (3, 3), activation='relu', padding='same', strides=2)])\n",
    "\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "            layers.Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "            layers.Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same')])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "conv_autoencoder = ConvAutoencoder(latent_dim)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "conv_autoencoder.compile(optimizer=opt, loss=losses.MeanSquaredError(), run_eagerly=True)\n",
    "conv_autoencoder.fit(layer(X_nomt_train), layer(X_nomt_train),\n",
    "                     epochs=50,\n",
    "                     batch_size=32,\n",
    "                     shuffle=True,\n",
    "                     validation_data=(layer(X_nomt_test[:1000]), layer(X_nomt_test[:1000])))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "err = []\n",
    "err2 = []\n",
    "for i in X_nomt_train:\n",
    "    # need to expand here because the flatten layer assumes that the first dimension is the number of samples\n",
    "    i = np.expand_dims(i, axis=0)\n",
    "    encoded = conv_autoencoder.encoder(layer(i)).numpy()\n",
    "    decoded = conv_autoencoder.decoder(encoded).numpy()\n",
    "    #print(\"Error:\",(np.square(i-decoded)).mean())\n",
    "    err.append((np.square(layer(i) - decoded)).mean())\n",
    "print(\"###################\")\n",
    "\n",
    "for j in X_free_test:\n",
    "    j = np.expand_dims(j, axis=0)\n",
    "    encoded = conv_autoencoder.encoder(layer1(j)).numpy()\n",
    "    decoded = conv_autoencoder.decoder(encoded).numpy()\n",
    "    #print(\"Error:\",(np.square(layer(j)-decoded)).mean())\n",
    "    err2.append((np.square(layer1(j) - decoded)).mean())\n",
    "print(\"##############\")\n",
    "print(np.array(err).mean())\n",
    "print(np.array(err2).mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "calc_accuracy(err, err2, np.mean([np.array(err).mean(), np.array(err2).mean()]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(err[:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1,1,1,1,1,1,,0,1,1,1 9/10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(err2[:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aa137f996c322d810b0ba78b9855db9c260b81f9ff796e150df9906e831bb7ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}